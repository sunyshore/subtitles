import time
import math
import ffmpeg

from faster_whisper import WhisperModel

input_video = "kie_jo.mp4"
input_video_name = input_video.replace(".mp4", "")

def transcribe(audio):
    model = WhisperModel("small")
    segments, info = model.transcribe(audio, language='si')
    language = info[0]
    print("Transcription language", info[0])
    print("Detected language '%s' with probability %f" % (info.language, info.language_probability))
    segments = list(segments)
    for segment in segments:
        # print(segment)
        print("[%.2fs -> %.2fs] %s" %
              (segment.start, segment.end, segment.text))
    return language, segments


def extract_audio(input_video_name):
    extracted_audio = f"audio-{input_video_name}.wav"
    stream = ffmpeg.input(input_video)
    stream = ffmpeg.output(stream, extracted_audio)
    ffmpeg.run(stream, overwrite_output=True)
    return extracted_audio

def format_time(seconds):
    hours = math.floor(seconds / 3600)
    seconds %= 3600
    minutes = math.floor(seconds / 60)
    seconds %= 60
    milliseconds = round((seconds - math.floor(seconds)) * 1000)
    seconds = math.floor(seconds)
    formatted_time = f"{hours:02d}:{minutes:02d}:{seconds:01d},{milliseconds:03d}"
    return formatted_time

def generate_subtitle_file(language, segments):
    subtitle_file = f"sub-{input_video_name}.{language}.srt"
    text = ""
    for index, segment in enumerate(segments):
        segment_start = format_time(segment.start)
        segment_end = format_time(segment.end)
        text += f"{str(index+1)}\n"
        text += f"{segment_start} --> {segment_end}\n"
        text += f"{segment.text}\n"
        text += "\n"
        
    f = open(subtitle_file, "w")
    f.write(text)
    f.close()

    return subtitle_file


extracted_audio = extract_audio(input_video_name)
language, segments = transcribe(audio=extracted_audio)

subtitle_file = generate_subtitle_file(
    language=language,
    segments=segments
    )